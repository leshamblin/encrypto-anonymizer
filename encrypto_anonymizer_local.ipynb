{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîê Encrypto-Anonymizer (Local Version)\n",
    "\n",
    "**A locally-running tool to anonymize and encrypt CSV data securely.**\n",
    "\n",
    "## üîí About the Encrypto-Anonymizer\n",
    "- All files are processed locally on your machine\n",
    "- No data is uploaded to any cloud service\n",
    "- Files are stored only where you explicitly save them\n",
    "- Perfect for sensitive student data or any confidential information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup: Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages using pip\n",
    "# If using UV, you can add these to your pyproject.toml instead\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas cryptography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Step 1: Load a CSV file from local filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 6) (2080404564.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mcsv_path = \"/Users/wjs/Downloads/anonymizer.csv'\u001B[39m\n               ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m unterminated string literal (detected at line 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_path = \"FILE.CSV\"\n",
    "csv_path = Path(csv_path).expanduser()  # Handle ~ in paths\n",
    "\n",
    "if not csv_path.exists():\n",
    "    print(f\"Error: File not found at {csv_path}\")\n",
    "else:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded {len(df)} rows from {csv_path.name}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(df.head())\n",
    "    print(\"\\nColumn names:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 2: Select columns to anonymize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can modify this list or make it interactive\n",
    "columns_to_anonymize = ['Name', 'Email', 'ID']  # Change as needed\n",
    "\n",
    "# Interactive column selection\n",
    "print(\"Available columns:\", list(df.columns))\n",
    "print(\"\\nCurrent columns to anonymize:\", columns_to_anonymize)\n",
    "print(\"\\nWould you like to modify the columns to anonymize? (y/n)\")\n",
    "if input().lower() == 'y':\n",
    "    columns_to_anonymize = []\n",
    "    print(\"Enter column names one by one (press Enter without text to finish):\")\n",
    "    while True:\n",
    "        col = input().strip()\n",
    "        if not col:\n",
    "            break\n",
    "        if col in df.columns:\n",
    "            columns_to_anonymize.append(col)\n",
    "        else:\n",
    "            print(f\"Warning: '{col}' not found in dataframe\")\n",
    "\n",
    "print(\"Selected columns to anonymize:\", columns_to_anonymize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÄ Step 3: Anonymize and create encrypted mapping\n",
    "\n",
    "**Options:**\n",
    "- `use_composite_key = True`: Creates a single anonymous ID for all selected columns in a row (linked anonymization)\n",
    "- `use_composite_key = False`: Creates separate anonymous IDs for each value (traditional behavior)\n",
    "\n",
    "The code now:\n",
    "- Checks if values already exist in the mapping to avoid duplicates\n",
    "- Can create composite keys for multiple fields\n",
    "- Maintains a reverse mapping for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from cryptography.fernet import Fernet\n",
    "import json\n",
    "\n",
    "# Generate a secure encryption key\n",
    "fernet_key = Fernet.generate_key()\n",
    "fernet = Fernet(fernet_key)\n",
    "\n",
    "# Single mapping dictionary to store all mappings\n",
    "mapping = {}\n",
    "# Reverse mapping to check if a value already has an ID\n",
    "reverse_mapping = {}\n",
    "\n",
    "anon_df = df.copy()\n",
    "\n",
    "# Check if we want to create a composite key for all selected columns\n",
    "use_composite_key = True  # Set to False if you want separate mappings per value\n",
    "\n",
    "if use_composite_key and len(columns_to_anonymize) > 1:\n",
    "    # Create composite key based on all selected columns\n",
    "    print(\"Using composite key for multiple columns...\")\n",
    "    for index in range(len(df)):\n",
    "        # Create a composite key from all anonymized columns for this row\n",
    "        composite_parts = []\n",
    "        for col in columns_to_anonymize:\n",
    "            val = str(df.iloc[index][col])\n",
    "            composite_parts.append(val)\n",
    "        \n",
    "        # Create a unique identifier for this combination\n",
    "        composite_key = \"|\".join(composite_parts)\n",
    "        \n",
    "        # Check if this combination already has an ID\n",
    "        if composite_key in reverse_mapping:\n",
    "            anon_id = reverse_mapping[composite_key]\n",
    "        else:\n",
    "            anon_id = str(uuid.uuid4())\n",
    "            # Encrypt each value separately but store under same ID\n",
    "            encrypted_values = {}\n",
    "            for i, col in enumerate(columns_to_anonymize):\n",
    "                encrypted_val = fernet.encrypt(composite_parts[i].encode()).decode()\n",
    "                encrypted_values[col] = encrypted_val\n",
    "            \n",
    "            mapping[anon_id] = encrypted_values\n",
    "            reverse_mapping[composite_key] = anon_id\n",
    "        \n",
    "        # Apply the same anonymous ID to all columns for this row\n",
    "        for col in columns_to_anonymize:\n",
    "            anon_df.loc[index, col] = anon_id\n",
    "else:\n",
    "    # Original behavior - separate mapping per value\n",
    "    print(\"Using separate mappings per value...\")\n",
    "    for col in columns_to_anonymize:\n",
    "        new_ids = []\n",
    "        for val in df[col]:\n",
    "            str_val = str(val)\n",
    "            \n",
    "            # Check if this value already has a mapping\n",
    "            if str_val in reverse_mapping:\n",
    "                anon_id = reverse_mapping[str_val]\n",
    "            else:\n",
    "                anon_id = str(uuid.uuid4())\n",
    "                encrypted_val = fernet.encrypt(str_val.encode()).decode()\n",
    "                mapping[anon_id] = encrypted_val\n",
    "                reverse_mapping[str_val] = anon_id\n",
    "            \n",
    "            new_ids.append(anon_id)\n",
    "        anon_df[col] = new_ids\n",
    "\n",
    "# Save files to a specified directory\n",
    "output_dir = Path(input(\"Enter output directory (default: current directory): \").strip() or \".\")\n",
    "output_dir = output_dir.expanduser()\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save anonymized data\n",
    "anon_path = output_dir / \"anonymized.csv\"\n",
    "anon_df.to_csv(anon_path, index=False)\n",
    "\n",
    "# Save mapping\n",
    "mapping_path = output_dir / \"mapping.json\"\n",
    "with open(mapping_path, \"w\") as f:\n",
    "    json.dump(mapping, f, indent=2)\n",
    "\n",
    "# Save encryption key\n",
    "key_path = output_dir / \"key.key\"\n",
    "with open(key_path, \"wb\") as f:\n",
    "    f.write(fernet_key)\n",
    "\n",
    "print(f\"‚úÖ Done anonymizing. Files saved to:\")\n",
    "print(f\"  - Anonymized data: {anon_path}\")\n",
    "print(f\"  - Mapping: {mapping_path}\")\n",
    "print(f\"  - Encryption key: {key_path}\")\n",
    "print(\"\\n‚ö†Ô∏è  Keep the mapping.json and key.key files secure!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîì Step 4: Load anonymized file + mapping + key to de-anonymize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files for de-anonymization\n",
    "print(\"Enter paths to the required files:\")\n",
    "anon_path = Path(input(\"Anonymized CSV file: \").strip()).expanduser()\n",
    "mapping_path = Path(input(\"Mapping JSON file: \").strip()).expanduser()\n",
    "key_path = Path(input(\"Encryption key file: \").strip()).expanduser()\n",
    "\n",
    "# Verify files exist\n",
    "missing_files = []\n",
    "for path, name in [(anon_path, \"Anonymized CSV\"), (mapping_path, \"Mapping\"), (key_path, \"Key\")]:\n",
    "    if not path.exists():\n",
    "        missing_files.append(f\"{name}: {path}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(\"Error: The following files were not found:\")\n",
    "    for f in missing_files:\n",
    "        print(f\"  - {f}\")\n",
    "else:\n",
    "    # Load the files\n",
    "    anon_df = pd.read_csv(anon_path)\n",
    "    \n",
    "    with open(mapping_path) as f:\n",
    "        mapping = json.load(f)\n",
    "    \n",
    "    with open(key_path, \"rb\") as f:\n",
    "        fernet = Fernet(f.read())\n",
    "    \n",
    "    print(\"‚úÖ Files loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ Step 5: De-anonymize and restore original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_df = anon_df.copy()\n",
    "\n",
    "# Automatically detect which columns were anonymized\n",
    "# (columns that contain UUID-like values)\n",
    "import re\n",
    "uuid_pattern = re.compile(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$')\n",
    "\n",
    "anonymized_columns = []\n",
    "for col in anon_df.columns:\n",
    "    # Check if the first non-null value looks like a UUID\n",
    "    first_val = anon_df[col].dropna().iloc[0] if not anon_df[col].dropna().empty else None\n",
    "    if first_val and isinstance(first_val, str) and uuid_pattern.match(first_val):\n",
    "        anonymized_columns.append(col)\n",
    "\n",
    "print(f\"Detected anonymized columns: {anonymized_columns}\")\n",
    "\n",
    "# De-anonymize the detected columns\n",
    "for col in anonymized_columns:\n",
    "    original_values = []\n",
    "    for anon_id in anon_df[col]:\n",
    "        if pd.isna(anon_id):\n",
    "            original_values.append(None)\n",
    "        elif anon_id in mapping:\n",
    "            if isinstance(mapping[anon_id], dict):\n",
    "                # Composite key mapping - extract value for specific column\n",
    "                if col in mapping[anon_id]:\n",
    "                    encrypted_val = mapping[anon_id][col]\n",
    "                    decrypted_val = fernet.decrypt(encrypted_val.encode()).decode()\n",
    "                else:\n",
    "                    decrypted_val = anon_id  # Column not in mapping, keep as is\n",
    "            else:\n",
    "                # Simple mapping - decrypt direct value\n",
    "                decrypted_val = fernet.decrypt(mapping[anon_id].encode()).decode()\n",
    "            original_values.append(decrypted_val)\n",
    "        else:\n",
    "            print(f\"Warning: No mapping found for ID {anon_id}\")\n",
    "            original_values.append(anon_id)\n",
    "    \n",
    "    restored_df[col] = original_values\n",
    "\n",
    "# Save restored file\n",
    "output_path = Path(input(\"Enter path for restored CSV (default: restored.csv): \").strip() or \"restored.csv\")\n",
    "output_path = output_path.expanduser()\n",
    "restored_df.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Restoration complete. File saved to: {output_path}\")\n",
    "print(\"\\nFirst 5 rows of restored data:\")\n",
    "display(restored_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encrypto-anonymizer",
   "language": "python",
   "name": "encrypto-anonymizer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
